{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a08421a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-10</td>\n",
       "      <td>Загрузка, парсинг и визуализация данных без пр...</td>\n",
       "      <td>https://habr.com/ru/company/tablum/blog/594643/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-06</td>\n",
       "      <td>Дорожная карта по изучению python</td>\n",
       "      <td>https://habr.com/ru/post/593703/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                              title  \\\n",
       "0  2021-12-10  Загрузка, парсинг и визуализация данных без пр...   \n",
       "0  2021-12-06                  Дорожная карта по изучению python   \n",
       "\n",
       "                                              link  \n",
       "0  https://habr.com/ru/company/tablum/blog/594643/  \n",
       "0                 https://habr.com/ru/post/593703/  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Задание 1.\n",
    "Обязательная часть\n",
    "Будем парсить страницу со свежеми новостям на habr.com/ru/all/.\n",
    "\n",
    "Вам необходимо собирать только те статьи, в заголовке которых встречается хотя бы одно требуемое ключевое слово.\n",
    "Эти слова определяем в начале кода в переменной, например:\n",
    "KEYWORDS = ['python', 'парсинг']\n",
    "\n",
    "В итоге должен формироваться датафрейм вида: <дата> - <заголовок> - <ссылка>\n",
    "Дополнительная часть (необязательная)\n",
    "Улучшить скрипт так, чтобы он анализировал не только заголовки статьи, но и весь текст статьи целиком.\n",
    "Для этого потребуется получать страницы статей и искать по тексту внутри этой страницы.\n",
    "Итоговый датафрейм формировать со столбцами: <дата> - <заголовок> - <ссылка> - <текст_статьи>\n",
    "\"\"\"\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "def get_url():\n",
    "    return 'https://habr.com/ru/all'\n",
    "\n",
    "\n",
    "def get_soup(page=None):\n",
    "    str_page = ''\n",
    "    if page:\n",
    "        str_page = f'page{page}/'\n",
    "    url = f'{get_url()}/{str_page}'\n",
    "    req = requests.get(url)\n",
    "    time.sleep(0.2)\n",
    "    return BeautifulSoup(req.text, 'html.parser')\n",
    "\n",
    "\n",
    "habr_news = pd.DataFrame()\n",
    "KEYWORDS = {'python', 'парсинг'}\n",
    "\n",
    "next_page = 1\n",
    "max_pg = 1\n",
    "# производим поиск во всех доступных страницах\n",
    "all_posts = []\n",
    "while next_page <= max_pg:\n",
    "    if next_page == 1:\n",
    "        soup = get_soup()\n",
    "    else:\n",
    "        soup = get_soup(next_page)\n",
    "\n",
    "    pg_list = soup.find_all('a', class_='tm-pagination__page')\n",
    "    max_pg = int(re.sub(r\"[^0-9]\", '', pg_list[len(pg_list) - 1].text))\n",
    "    next_page += 1\n",
    "\n",
    "    posts = soup.find_all('a', class_='tm-article-snippet__title-link')\n",
    "    for post in posts:\n",
    "        post_list = set([x for x in post.find('span').text.split(' ')])\n",
    "        if any(elem in KEYWORDS for elem in post_list):\n",
    "            date = pd.to_datetime(post.parent.parent.find('span', class_='tm-article-snippet__datetime-published').\n",
    "                                  find('time').\n",
    "                                  get('datetime'),\n",
    "                                  dayfirst=True).date()\n",
    "\n",
    "            title = post.find('span').text\n",
    "            link_ = f'https://habr.com{post.get(\"href\")}'\n",
    "            # print(f'date: {date}, title: {title}, link: {link_}')\n",
    "            row = {'date': date, 'title': title, 'link': link_}\n",
    "            habr_news = pd.concat([habr_news, pd.DataFrame([row])])\n",
    "\n",
    "\n",
    "habr_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a78086cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "           mail           publishDate  publishedSource  \\\n",
      "0  gena@mail.ru  2019-08-08T00:00:00Z      borealis.su   \n",
      "0  gena@mail.ru  2020-07-23T00:00:00Z      wattpad.com   \n",
      "0  gena@mail.ru  2019-12-05T00:00:00Z  wowprogress.com   \n",
      "0  gena@mail.ru  2020-12-17T00:00:00Z    belarusgo.com   \n",
      "0  gena@mail.ru  2020-12-17T00:00:00Z   forum.nedug.ru   \n",
      "\n",
      "                                         description  \n",
      "0  At an unconfirmed date, Russian Minecraft serv...  \n",
      "0  In June 2020, the online writing community Wat...  \n",
      "0  At an unconfirmed date, the World of Warcraft ...  \n",
      "0  In November 2020, a collection of over 23,000 ...  \n",
      "0  In November 2020, a collection of over 23,000 ...  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Задание 2.\n",
    "Обязательная часть\n",
    "Написать скрипт, который будет проверять список e-mail адресов на утечку при помощи сервиса Avast Hack Ckeck. \n",
    "Список email-ов задаем переменной в начале кода:\n",
    "EMAIL = [xxx@x.ru, yyy@y.com]\n",
    "\n",
    "В итоге должен формироваться датафрейм со столбцами: <дата утечки> - <источник утечки> - <описание утечки>\n",
    "\n",
    "Подсказка: сервис работает при помощи “скрытого” API. Внимательно изучите post-запросы.\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "url_ = 'https://identityprotection.avast.com/v1/web/query/site-breaches/unauthorized-data'\n",
    "header_ = {\n",
    "    'Accept': 'application/json, text/plain, */*',\n",
    "    'Content-Type': 'application/json;charset=UTF-8',\n",
    "    'Host': 'identityprotection.avast.com',\n",
    "    'Origin': 'https://www.avast.com',\n",
    "    'Referer': 'https://www.avast.com/',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36',\n",
    "    'Vaar-Header-App-Build-Version': '1.0.0',\n",
    "    'Vaar-Header-App-Product-Name': 'hackcheck-web-avast',\n",
    "    'Vaar-Version': '0'\n",
    "}\n",
    "params_ = {\n",
    "    'emailAddresses': ['gena@mail.ru', 'gennadiy@gmail.com']\n",
    "}\n",
    "df = pd.DataFrame()\n",
    "res = requests.post(url=url_, headers=header_, json=params_)\n",
    "time.sleep(0.2)\n",
    "print(res.status_code)\n",
    "json_data = res.json()\n",
    "if res.status_code == 200 and json_data is not None:\n",
    "    for mail_ in json_data['summary']:\n",
    "        for b in json_data['breaches']:\n",
    "            if int(b) in json_data['summary'][mail_]['breaches']:            \n",
    "                row = {'mail': mail_,\n",
    "                       'publishDate': json_data['breaches'][b]['publishDate'],\n",
    "                       'publishedSource': json_data['breaches'][b]['site'],\n",
    "                       'description': json_data['breaches'][b]['description']\n",
    "                       }\n",
    "                df = pd.concat([df, pd.DataFrame([row])])\n",
    "\n",
    "    print(df.head())\n",
    "else:\n",
    "    print(res.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71034a1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
